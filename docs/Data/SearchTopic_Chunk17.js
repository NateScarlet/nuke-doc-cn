define({"1192":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_disparitytodepth2_0.html",a:"C_DisparityToDepth is a gizmo designed to convert disparity to a depth map. Depth maps can be useful in compositing when you\u0027re placing 3D objects in a scene. Getting the depth right can help achieve a more realistic look. See the CaraVR  Online Help  for more information on C_DisparityToDepth. ...",t:"C_DisparityToDepth"},"1193":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_generatemap2_0.html",a:"C_GenerateMap allows you to generate stitch_map and ppass_map channels. The stitch_map UV channels represent the absolute pixel positions of an image normalized between 0 and 1, whereas the ppass_map XYZ channels represent the normalized 3D coordinates of a latlong image ranging between -1 and 1. ...",t:"C_GenerateMap"},"1194":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_globalwarp2_0.html",a:"C_GlobalWarp rapidly produces a preview stitch using metadata, passed downstream from a C_CameraSolver, to help minimize ghosting in overlap regions. It includes controls to adjust a stitch to line up key features and allows you to add constraints to reduce warping on known straight lines in the ...",t:"C_GlobalWarp"},"1195":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_newview2_0.html",a:"Use the C_NewView node to reconstruct a view using the pixels from another view. For example, you can choose to reconstruct the left view using the pixels from the right view. This can be useful if you want to manipulate one view (with a gizmo, node, or graphics editor for example) and replicate the ...",t:"C_NewView"},"1196":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_rayrender2_0.html",a:"C_RayRender is based on the vanilla Nuke RayRender node, but it also includes a Camera tab to reconstruct stereographic VR sequences using slit scan techniques. Ray rendering is a 3D to 2D process, so there\u0027s some setup involved before you can use C_RayRender. When connected to a Scene node, the ...",t:"C_RayRender"},"1197":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_sphericaltransform2_0.html",a:"C_SphericalTransform converts images between different projections, similar to the vanilla Nuke SphericalTransform node, but designed for 360 work and including Blink GPU acceleration. These view projections can be divided into two broad categories: full frame, such as Latlong, encompassing the ...",t:"C_SphericalTransform"},"1198":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_stereocolourmatcher2_0.html",a:"The C_StereoColourMatcher node enables you match the colors of one view with those of another. It has been specifically designed to deal with the subtle  color differences that are sometimes present between stereo views. C_StereoColourMatcher requires disparity vectors from an upstream ...",t:"C_StereoColourMatcher"},"1199":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_stitcher2_0.html",a:"C_Stitcher uses Ocula-style disparity vectors to line up matched features in the overlap areas between overlapping cameras and then blends the results to generate a spherical latlong. C_Stitcher requires a C_CameraSolver upstream to generate an image. See the CaraVR  Online Help  for more ...",t:"C_Stitcher"},"1200":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_stmap2_0.html",a:"The C_STMap node is a GPU accelerated version of Nuke\u0027s standard STMap node. The C_STMap node allows you to warp the src input according to the stitch or ppass attached to the map input. C_STMap accepts stitch_map and ppass_map channels in specified layers. The stitch_map UV channels represent the ...",t:"C_STMap"},"1201":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_0/c_tracker2_0.html",a:"C_Tracker automatically extracts animation data from the pan, tilt, and roll of a pattern to simplify and accelerate the process of stabilization and matchmoving. You can then use user defined tracks to improve the result or lock stabilization to particular regions. C_Tracker differs from vanilla ...",t:"C_Tracker"},"1202":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/caravr_nodes.html",a:"CaraVR 2.1 Nodes CaraVR nodes are only available if you have a CaraVR license for Nuke.",t:"CaraVR 2.1 Nodes"},"1203":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_alphagenerator2_1.html",a:"C_AlphaGenerator creates a rectangular or elliptical mask in the alpha channel. It\u0027s primarily used for manual stitching and is included in the Manual 2D and 3D Stitching toolsets included in C_CameraSolver\u0027s Export dropdown. Inputs and Controls Control (UI) Knob (Scripting) Default Value Function ...",t:"C_AlphaGenerator"},"1204":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_bilateral2_1.html",a:"C_Bilateral is a smoothing filter that operates by mixing nearby source pixels according to their spatial distance and color similarity. The filter is particularly good at preserving edges, though it can be computationally expensive. \t\tIt\u0027s similar to the standard Nuke Bilateral node, but with the ...",t:"C_Bilateral"},"1205":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_blender2_1.html",a:"C_Blender is used as a Merge node to combine all images together when manually correcting a stitch. The C_Stitcher can output separate warped images, which can be corrected manually to remove vertical misalignment, edited to control the seam between different images, and then finally combined by ...",t:"C_Blender"},"1206":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_blur2_1.html",a:"C_Blur allows you to apply blur to a latlong image and produce a sensible result across the entire frame, as if it were applied to a rectilinear image all around.  Adds blur to an image or matte using Box or Gaussian filter algorithms. The blur value is calculated for image pixels by examining their ...",t:"C_Blur"},"1207":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_cameraingest2_1.html",a:"C_CameraIngest streamlines import workflows when using manually solved or pre-tracked footage from third-party applications. Connect your cameras and your footage to the node to setup a rig that can be used directly for stitching, or as the basis for further refinement with the C_CameraSolver. ...",t:"C_CameraIngest"},"1208":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_camerasolver2_1.html",a:"CaraVR\u0027s C_CameraSolver node creates an approximate camera geometry, relative to a nodal point or a sphere, for multi-camera rigs. This defines the location and orientation preview for each camera so that the images can be stitched by C_Stitcher for output. Inputs and Controls Control (UI) Knob ...",t:"C_CameraSolver"},"1209":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_colourmatcher2_1.html",a:"C_ColourMatcher aims to produce a global gain-based color correction across all the views in a rig to balance out differences in exposure and white balance. It solves across all cameras to find the minimum required gain changes to ensure color similarity. C_ColourMatcher does not compensate for ...",t:"C_ColourMatcher"},"1210":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_disparitygenerator2_1.html",a:"The C_DisparityGenerator node is used to create disparity maps for stereo images. A disparity map describes the location of a pixel in one view in relation to the location of its corresponding pixel in the other view. It includes two sets of disparity vectors: one maps the left view to the right, ...",t:"C_DisparityGenerator"},"1211":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_disparitytodepth2_1.html",a:"C_DisparityToDepth is a gizmo designed to convert disparity to a depth map. Depth maps can be useful in compositing when you\u0027re placing 3D objects in a scene. Getting the depth right can help achieve a more realistic look. Inputs and Controls Control (UI) Knob (Scripting) Default Value Function ...",t:"C_DisparityToDepth"},"1212":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_generatemap2_1.html",a:"C_GenerateMap allows you to generate stitch_map and ppass_map channels. The stitch_map UV channels represent the absolute pixel positions of an image normalized between 0 and 1, whereas the ppass_map XYZ channels represent the normalized 3D coordinates of a latlong image ranging between -1 and 1. ...",t:"C_GenerateMap"},"1213":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_globalwarp2_1.html",a:"C_GlobalWarp rapidly produces a preview stitch using metadata, passed downstream from a C_CameraSolver, to help minimize ghosting in overlap regions. It includes controls to adjust a stitch to line up key features and allows you to add constraints to reduce warping on known straight lines in the ...",t:"C_GlobalWarp"},"1214":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_newview2_1.html",a:"Use the C_NewView node to reconstruct a view using the pixels from another view. For example, you can choose to reconstruct the left view using the pixels from the right view. This can be useful if you want to manipulate one view (with a gizmo, node, or graphics editor for example) and replicate the ...",t:"C_NewView"},"1215":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_rayrender2_1.html",a:"C_RayRender is based on the vanilla Nuke RayRender node, but it also includes a Camera tab to reconstruct stereographic VR sequences using slit scan techniques. Ray rendering is a 3D to 2D process, so there\u0027s some setup involved before you can use C_RayRender. When connected to a Scene node, the ...",t:"C_RayRender"},"1216":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_sphericaltransform2_1.html",a:"C_SphericalTransform converts images between different projections, similar to the vanilla Nuke SphericalTransform node, but designed for 360 work and including Blink GPU acceleration. These view projections can be divided into two broad categories: full frame, such as Latlong, encompassing the ...",t:"C_SphericalTransform"},"1217":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_stereocolourmatcher2_1.html",a:"The C_StereoColourMatcher node enables you match the colors of one view with those of another. It has been specifically designed to deal with the subtle  color differences that are sometimes present between stereo views. C_StereoColourMatcher requires disparity vectors from an upstream ...",t:"C_StereoColourMatcher"},"1218":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_stitcher2_1.html",a:"C_Stitcher uses Ocula-style disparity vectors to line up matched features in the overlap areas between overlapping cameras and then blends the results to generate a spherical latlong. C_Stitcher requires a C_CameraSolver upstream to generate an image. Inputs and Controls Control (UI) Knob ...",t:"C_Stitcher"},"1219":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_stmap2_1.html",a:"The C_STMap node is a GPU accelerated version of Nuke\u0027s standard STMap node. The C_STMap node allows you to warp the src input according to the stitch or ppass attached to the map input. C_STMap accepts stitch_map and ppass_map channels in specified layers. The stitch_map UV channels represent the ...",t:"C_STMap"},"1220":{i:0.000594774497125944,u:"../content/reference_guide/cara_vr2_1/c_tracker2_1.html",a:"C_Tracker automatically extracts animation data from the pan, tilt, and roll of a pattern to simplify and accelerate the process of stabilization and matchmoving. You can then use user defined tracks to improve the result or lock stabilization to particular regions. C_Tracker differs from vanilla ...",t:"C_Tracker"},"1221":{i:0.000321498003524325,u:"../content/reference_guide/cara_vr2_1/c_verticalaligner2_1.html",a:"C_VerticalAligner, based on Ocula\u0027s O_VerticalAligner, eliminates vertical differences between stereo camera pairs while maintaining horizontal pixel positions. C_VerticalAligner is predominantly designed for use in rectilinear space, but it can also warp in latlong space to provide better results ...",t:"C_VerticalAligner"},"1222":{i:0.000321498003524325,u:"../content/tutorials/tutorials.html",a:"Tutorials This section pulls together all the written and video tutorials dotted throughout the documentation into one, easy-to-find area.   If you\u0027d prefer to follow a written tutorial, see  Written Tutorials . If you\u0027d prefer to watch a video, see  Video Tutorials .",t:"Tutorials"},"1223":{i:0.000458136250325134,u:"../content/getting_started/tutorials/tutorials.html",a:"Welcome to the written tutorials!  Introduction If you’ve gone through the Getting Started section  - which we highly recommend - you already know something about Nuke.  These tutorials show how to pull everything together through a series of practical examples. You can also go through these ...",t:"Written Tutorials"},"1224":{i:0.000321498003524325,u:"../content/getting_started/tutorials/projects.html",a:"These tutorials include the following projects: Tutorial 1: Compositing Basics  explains the Nuke user interface, project workflow, and basic compositing tasks. Tutorial 2: 2D Point Tracking  demonstrates how to track image patterns, stabilize footage, lock down images for clean plates, and ...",t:"The Projects"},"1225":{i:0.000652846574835016,u:"../content/getting_started/tutorials/installing_project_files.html",a:"Before you continue, download the tutorial project files from our website and move them to a directory you’ll create, called “Nuke_Tutorials”. It’s up to you where you put your tutorial files, but here’s our recommendations below depending on your operating system. Whatever you do, you’ll need to ...",t:"Installing the Project Files"},"1226":{i:0.000389817126924729,u:"../content/getting_started/tutorial1/compositing_basics.html",a:"Hello! This tutorial is your introduction to Nuke, where you’ll create a simple composite and breeze through most of the windows, on-screen controls, and other user interface items. Introduction We’ve heard rumors that many people would rather march through icy rain than review an introductory ...",t:"Tutorial 1: Compositing Basics"},"1227":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/starting_nuke.html",a:"The Nuke icon may appear on your desktop. If so, double-click it to launch the application. Otherwise, start Nuke with one of the methods described below, assuming you have installed Nuke to the default location. To Launch  Under Windows From the Start menu, choose All Programs \u003e The Foundry, and ...",t:"Starting Nuke"},"1228":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/using_toolbar.html",a:"The Toolbar includes the options you can use to build your project, such as importing images, layering images, drawing shapes and masks, applying color correction, and so on. Each Toolbar icon displays a menu of operators or nodes that you can select. Roll the mouse pointer over the Toolbar and ...",t:"Using the Toolbar"},"1229":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/using_menus.html",a:"The Nuke menu bar appears at the top of your screen, outside the main window. This menu begins with the options File, Edit, Workspace, and so on. When instructed to do so, make selections from the menu bar, or click the right mouse button to choose from a pop-up version of the menu bar. The ...",t:"Using the Menus"},"1230":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/customizing_your_layout.html",a:"Nuke gives you several options for customizing the window layout. It’s time for you to claim your copy of Nuke and make it your own! You don’t need to customize the layout for this lesson, but why not try it now for your own personal amusement? Here are some things you can do to reorganize the ...",t:"Customizing Your Workspace"},"1231":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/saving_files_backup.html",a:"We assume you already know how to save files (Hint: choose File \u003e Save Comp As). In addition, Nuke includes an autosave feature, which helps recover project files after a system failure. Yes, we know that never happens to you, but in the unlikely event that it does, you won’t lose your work when you ...",t:"Saving Files and File Backup"},"1232":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/setting_up_project.html",a:"When you start a new project, you need to define project settings for length or frame range, the number of frames per second for playback, and the output format. These options appear on the Project Settings dialog box.  To Set Up Your Project Click the right mouse button over the Node Graph, and ...",t:"Setting Up the Project"},"1233":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/working_nodes.html",a:"A node is simply one of the building blocks for the list of operations you want to complete. A node tree is a diagram that shows the order in which the operations are performed. Do the following to add a few nodes and start your node tree. The result creates the background for the project.  ...",t:"Working with Nodes"},"1234":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/connection_tips.html",a:"Most nodes have input and output connectors that are used to establish the order in which the operations are calculated. Try the following to connect nodes after you insert them into the Node Graph:  Drag an input or an output connector onto another node to establish a connection.  Select a node, ...",t:"Connection Tips"},"1235":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/importing_image_sequences.html",a:"For this project, you need to import a few image sequences for the foreground elements and a background plate.  To Read the Images Click on a blank space in the Node Graph. This ensures none of the nodes are selected.  Click the right mouse button over the Node Graph and choose Image \u003e Read (or ...",t:"Importing Image Sequences"},"1236":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/navigating_inside_windows.html",a:"The Node Graph panel can seem very small, especially when your node tree grows. True, you already know how to resize and tear-off the windows, but sooner or later you may run out of display real estate. It’s time to learn some navigation controls that can help you work in the Node Graph (and other ...",t:"Navigating Inside the Windows"},"1237":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/working_viewers.html",a:"The postage stamps on the nodes - those little pictures, often called thumbnails - show what each node passes onto the next node in the tree. Although quite lovely, they won’t do for real compositing work. You need to open a Viewer window to see the full picture. You can open several Viewers at ...",t:"Working with Viewers"},"1238":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/displaying_images_viewer.html",a:"To display the images in a Viewer window: Drag the connector from the Viewer node onto the Read node for the engine.v01 clip.  Here’s an alternate method: Select the engine.v01 clip node and then press 1 to connect to the Viewer node. Nuke displays the node’s output in the Viewer window.  Press the ...",t:"Displaying the Images in a Viewer Window"},"1239":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/viewing_multiple_inputs.html",a:"To view multiple inputs: Select the Read node for the smoke_left clip, and press 2 at the top of your keyboard or on the numeric key pad.  This creates a second connection to the Viewer from the selected node. When the cursor is over the Viewer, you can press a number on the keyboard to pick the ...",t:"Viewing Multiple Inputs"},"1240":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/reformatting_images.html",a:"Elements created within the Nuke script, such as Background and Ramp, automatically inherit the global format and that’s how you want it for this project. The imported images, however, do not conform to the project settings and must be reformatted.  To Conform Images to the Project Format Click the ...",t:"Reformatting Images"},"1241":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/using_proxies_downres.html",a:"Proxies are low-resolution versions of the final image you intend to create. For many compositing tasks, the low-res version can help you work faster. Then, when you’re ready to create the final output, switch proxy mode off and return to the full-res version.  Nuke can generate proxies on-the-fly, ...",t:"Using Proxies and “Down-res”"},"1242":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/compositing_images.html",a:"The Merge nodes create a composite with two or more images, using various compositing algorithms. In this example, we’ll do a very simple “A over B” composite to layer the foreground image over the background.  You can insert a compositing node from the Toolbar or menus, but we’ll show you a ...",t:"Compositing Images"},"1243":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/color_correcting_images.html",a:"Color-correction and filters can help you integrate the elements for a better composite. In our example, you want to limit the correction to the foreground element only, so you’ll insert a color correction node before the Merge nodes.  Select the Reformat1 node. Then, right-click over the Node Graph ...",t:"Color-Correcting Images"},"1244":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/masking_effects.html",a:"You can apply masks to limit how each of these nodes affects the images. The following shows how to create a Bezier mask to limit color-correction.  To Create and Apply a Bezier Mask To create and apply a Bezier mask: Click on a blank space in the Node Graph, so that nothing is selected in the node ...",t:"Masking Effects"},"1245":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/creating_flipbook_previews.html",a:"On the Viewer window, the timeline buttons let you play the project, but if you pay attention to the frames-per-second (FPS) field at the top of the Viewer window, you may notice that Nuke doesn’t provide real-time playback. This is because Nuke renders on-the-fly to display images in the Viewer. ...",t:"Creating Flipbook Previews"},"1246":{i:0.000321498003524325,u:"../content/getting_started/tutorial1/tut1_epilogue.html",a:"In this tutorial, you set up a new project and created a simple composite. You learned how to use (or at least, locate) practically every Nuke window and tool, and you rendered out the result of your composite. You’re finished! Go home!  Well... there might be a few more things you want to know. ...",t:"Epilogue"},"1247":{i:0.000542437059518314,u:"../content/getting_started/tutorial2/tracking_stabilizing.html",a:"This tutorial teaches you how to use Nuke\u0027s Tracker node for tracking, stabilizing, and match-moving. Introduction Every filmmaker knows the challenges of putting together a vision. You may not have the money to build post-apocalyptic Montreal, but you might have enough to create it in post. You may ...",t:"Tutorial 2: 2D Point Tracking"},"1248":{i:0.000321498003524325,u:"../content/getting_started/tutorial2/1_2_3_4_point_tracks.html",a:"Before we get into the first example, let’s review a few tracking concepts. You can track as many features or patterns as required with the Tracker node in Nuke. How do you decide whether to track one, two, or more features? It depends on what you want to do with the data and the level of accuracy ...",t:"One-Point, Two-Point, Three-Point, Four"},"1249":{i:0.000321498003524325,u:"../content/getting_started/tutorial2/open_tut2_project_file.html",a:"In this tutorial, you work from a project file that already includes the node trees. Each tree is setup for the examples that follow.  To Open the Project File Launch the Nuke application and choose File \u003e Open Comp from the menu bar.  In the file browser, navigate to your  Nuke_Tutorials/Tracking/ ...",t:"Open the Tutorial Project File"},"1250":{i:0.0039637914589606,u:"../content/getting_started/tutorial2/tracking_single_feature.html",a:"In this first example you’ll learn how to set up a tracking anchor and then track a single feature, which is the most basic 2D tracking operation. After you achieve a solid track for one feature, you can build on that and track other features as needed.  Setting a Tracking Anchor In the project ...",t:"Tracking a Single Feature"},"1251":{i:0.000321498003524325,u:"../content/getting_started/tutorial2/tracking_obscured_features.html",a:"At the end of the previous example, you may have noticed the track was dropped at frame 58 when the feature moved off the screen. When features move out of frame, or become obscured by other elements in the image, you can use the track offset feature to pass the tracking operation to another feature ...",t:"Tracking Obscured Features"},"1252":{i:0.000321498003524325,u:"../content/getting_started/tutorial2/stabilizing_elements.html",a:"Stabilization is the process of removing motion - camera-shake, for example - and locking down the element for your composite. A one-point track provides enough information to stabilize horizontal and vertical motion along the image plane. A two-point track lets you stabilize horizontal and vertical ...",t:"Stabilizing Elements"},"1253":{i:0.000321498003524325,u:"../content/getting_started/tutorial2/matchmoving_elements.html",a:"Match-moving is the opposite of stabilization. The intent is to record and use the motion in an image and apply it to another element. In the following example, you’ll use the tracker to match-move and composite a mask image onto the performer in a background plate. To Match-Move an Element This ...",t:"Match-Moving Elements"},"1254":{i:0.000321498003524325,u:"../content/getting_started/tutorial2/tut2_epilogue.html",a:"Epilogue In this tutorial, you worked with several examples for the Tracker node. You learned how to record the locations for multiple features and you applied the tracking data for other tasks in the composite, such as stabilization and match-moving.",t:"Epilogue"},"1255":{i:0.000389817126924729,u:"../content/getting_started/tutorial3/keying_mattes.html",a:"This tutorial introduces you to keying in Nuke. You will learn how to use the Primatte, IBK, and Keyer nodes. Introduction Keying is one of those fundamental compositing skills. You can’t composite anything until you have mattes pulled for the elements you want to layer together. It’s nice to say ...",t:"Tutorial 3: Keying and Mattes"},"1256":{i:0.000321498003524325,u:"../content/getting_started/tutorial3/open_tut3_project_file.html",a:"The project file for this tutorial includes several node trees for the keying operations described in this chapter.  To Open the Project File Launch the Nuke application and choose File \u003e Open Comp from the menu bar.  In the file browser, navigate to your  Nuke_Tutorials/Keying/ folder, select the ...",t:"Open the Tutorial Project File"},"1257":{i:0.000520858088757809,u:"../content/getting_started/tutorial3/keying_primatte.html",a:"The Primatte keyer includes a quick “Auto-Compute” option that evaluates your image and determines a good baseline key. From there, you can easily tweak the settings and generate an acceptable matte.  The two examples in this section show how to pull a key with the Auto-Compute option (method 1), ...",t:"Keying with Primatte"},"1258":{i:0.000668436506867808,u:"../content/getting_started/tutorial3/image_based_keying.html",a:"Many keying tools, like Primatte, use a color-pick as the baseline for the matte extraction process and then require the artist to tweak the matte from that baseline. Nuke’s image-based keyer (IBK) uses the pixel values of the compositing images, instead of a color-pick, to generate the best matte ...",t:"Image-Based Keying"},"1259":{i:0.000321498003524325,u:"../content/getting_started/tutorial3/rotoscoping.html",a:"In this example, we’ll return to our first keying example to apply a garbage matte and clean-up the aquarium image.  To Draw a Garbage Matte  Go back to the node tree from the first example, and connect the Viewer to the Primatte1 node. Drag the time slider to frame 50.  Click an empty spot on the ...",t:"Rotoscoping"},"1260":{i:0.000594774497125944,u:"../content/getting_started/tutorial3/keying_video.html",a:"Nuke’s Keyer node provides standard controls for pulling luma keys, green and blue screens, and color channels. We’ll use this keyer - and a few other nodes - to handle a special keying situation: video.  We’ll begin by inserting a group of nodes that allow you to pull a cleaner matte by filtering ...",t:"Keying Video"},"1261":{i:0.000321498003524325,u:"../content/getting_started/tutorial3/tut3_epilogue.html",a:"Keying is rarely a simple matter of picking the screen color you want to remove. To get the very best mattes, you often need to combine several techniques and you’ve learned several in this chapter. You’ve pulled mattes with Primatte and Nuke’s Image-based Keyer, and you’ve used the rotoscoping ...",t:"Epilogue"},"1262":{i:0.000389817126924729,u:"../content/getting_started/tutorial4/3d_integration.html",a:"This tutorial teaches you the basics of using Nuke\u0027s 3D workspace. Introduction Nuke’s 3D workspace creates a powerful compositing environment within your project script. This workspace combines the advantages of cameras, lighting, and a three-axis (x, y, and z) environment, with the speed of ...",t:"Tutorial 4: 3D Integration"},});