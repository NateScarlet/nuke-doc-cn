define({"614":{i:0.000915181126517676,u:"../content/timeline_environment/exporting/write_node_settings.html",a:"Custom shot presets can only be selected from the Project Settings if they contain a Nuke Project File and Nuke Write Node Content preset. Click the Nuke Write Node Content preset to display the write settings. Set the following controls common to all file types: Channels - set the channels to ...",t:"Nuke Write Node Settings"},"615":{i:0.000580804839160723,u:"../content/timeline_environment/exporting/track_range_settings.html",a:"The tracks, tags, and handles controls in the Export dialog allow you to select the frame range or clip instances to export. Set the Version number for the export, if applicable. Use the arrows to increment the version number and the +/- buttons to increase or decrease the padding. You can also type ...",t:"Tracks, Range, and Handles Settings"},"616":{i:0.00713541033074563,u:"../content/timeline_environment/exporting/building_vfx_tracks.html",a:"When the compositing work is complete, the clips are ready to re-ingest. The shot template defines where the Nuke files reside, so all you need to do is instruct Nuke Studio to build tracks from previous exports. See  Building Tracks From Export Structure  for more information. Alternatively, if you ...",t:"Building VFX Tracks and Comp Clips"},"617":{i:0.00138222180167225,u:"../content/timeline_environment/exporting/transcoding.html",a:"Transcoding in Nuke Studio uses a background render process to convert one file format to another. You can transcode sequences, timeline selections, and clips from the bin view. Transcoding a Sequence Select a sequence in the bin view and navigate to File \u003e Export... The Export dialog displays. ...",t:"Transcoding"},"618":{i:0.000321498003524325,u:"../content/timeline_environment/exporting/transcoding_shots.html",a:"Select the required sequence in the bin view and navigate to File \u003e Export... The Export dialog displays. Select Process as Shots and use the default, Transcode Shots DPX, or build a shot template using the Path and Contents fields and the folder and +/- buttons. The default: Creates a folder for ...",t:"Transcoding a Sequence as Shots"},"619":{i:0.000321498003524325,u:"../content/timeline_environment/exporting/transcoding_timeline.html",a:"Transcoding an entire timeline can be time consuming, or even unnecessary, if all you’re looking for is a new version of a selection of clip instances. To transcode a selection of clips from a timeline: Select the required clip instances on the timeline. Right-click a highlighted item and select ...",t:"Transcoding Timeline Selections"},"620":{i:0.000321498003524325,u:"../content/timeline_environment/exporting/transcoding_bin.html",a:"To transcode directly from the bin view: Select the bin(s) to export from the bin view. Right-click a highlighted bin and select Export... The Export dialog displays. Select Process as Clips and modify the shot template, if required. Follow the steps under  Transcoding a Sequence    to complete the ...",t:"Transcoding from the Bin View"},"621":{i:0.00046218984278849,u:"../content/timeline_environment/exporting/ad_hoc_exports.html",a:"Ad Hoc Exports This section covers exports that you might not perform on a per project basis, such the EDL or XML Exporters and Copy Exporter. Exporters are available for sequences, clip instances, and clips as described in the following table.",t:"Ad Hoc Exports"},"622":{i:0.000564883204299727,u:"../content/timeline_environment/exporting/exporting_edls_and_xmls.html",a:"Nuke Studio supports export to EDL and XML using very similar methods, the main difference being that EDL doesn’t support multiple video tracks in a single file whereas XML does. Nuke Studio can read AAF files, but not write them out. To export to EDL or XML: Select a sequence in the bin view and ...",t:"Exporting EDLs and XMLs"},"623":{i:0.000321498003524325,u:"../content/timeline_environment/exporting/using_audio_exporter.html",a:"The Audio Exporter allows you write audio to separate .wav files. You can extract audio from whole sequences, clip instances, and source clips. Exporting Audio from Sequences Select a sequence in the bin view and navigate to File \u003e Export... The Export dialog displays. Select Process as Sequence ...",t:"Using the Audio Exporter"},"624":{i:0.000806637995668741,u:"../content/timeline_environment/exporting/using_copy_exporter.html",a:"Copying media from various locations is very time consuming and can waste disk space. The Copy Exporter allows you to consolidate sequences containing only your project media in a named file structure using the shot template. To copy media to a named location: Select a sequence in the bin view and ...",t:"Using the Copy Exporter"},"625":{i:0.000321498003524325,u:"../content/timeline_environment/exporting/using_symlink_exporter.html",a:"The SymLink Generator allows you to create symbolic links to your project media in a named file structure using the shot template. Windows only: Symbolic links are only supported by Windows Vista, or later. if you\u0027re linking across file systems, the remote file servers must also be running Windows ...",t:"Using the SymLink Generator"},"626":{i:0.00128999398449877,u:"../content/comp_environment/nukex/nukex_intro.html",a:"Each chapter in this section explains in detail a key feature of NukeX and Nuke Studio. For more information on the differences between the various applications, see  Nuke Products . Organization of the Section These are the topics covered by this section: VectorGenerator, Kronos, and MotionBlur - ...",t:"Advanced Compositing with NukeX and Nuke Studio"},"627":{i:0.000376324095958171,u:"../content/comp_environment/kronos_motionblur/motion_vectors_retiming_blur.html",a:"Retiming and Motion Blur This chapter looks at creating motion vectors using  VectorGenerator , retiming sequences using  Kronos , and adding motion blur using  MotionBlur .",t:"Retiming and Motion Blur"},"628":{i:0.00100977940372872,u:"../content/comp_environment/kronos_motionblur/vectorgenerator.html",a:"VectorGenerator allows you to produce images containing  motion vector fields. A vector field for an image in a sequence has the same dimensions as the image, but contains an (x,y) offset per pixel. These offsets show how to warp a neighboring image onto the current image. Clearly, as most of the ...",t:"VectorGenerator"},"629":{i:0.000321498003524325,u:"../content/comp_environment/kronos_motionblur/quick_start_vectorgenerator.html",a:"Here\u0027s a quick overview of the workflow: Add VectorGenerator to your node tree. See  Connecting VectorGenerator  below. View and refine the results. See  Viewing and Refining the Results . You can check Use GPU if available to have the node run on the graphics processing unit (GPU) rather than the ...",t:"Quick Start"},"630":{i:0.000412590168058198,u:"../content/comp_environment/kronos_motionblur/connecting_vectorgenerator.html",a:"To connect VectorGenerator: Select Time \u003e VectorGenerator to insert a VectorGenerator node after the sequence from which you want to generate motion vectors. Attach a Viewer to the output of the VectorGenerator node. If your sequence is composed of a foreground object moving over a background, the ...",t:"Connecting VectorGenerator"},"631":{i:0.000763296098605247,u:"../content/comp_environment/kronos_motionblur/viewing_refining_results.html",a:"To view and refine the results: Select the required vector calculation type from the Method dropdown: Local - uses local block matching to estimate motion vectors. This method is faster to process, but can lead to artifacts in the output. Regularized - uses semi-global motion estimation to produce ...",t:"Viewing and Refining the Results"},"632":{i:0.000947248495924178,u:"../content/comp_environment/kronos_motionblur/kronos.html",a:"Kronos is NukeX’s retimer, designed to slow down or speed up footage. It works by calculating the motion in the sequence in order to generate motion vectors. These motion vectors describe how each pixel moves from frame to frame. With accurate motion vectors, it is possible to generate an output ...",t:"Kronos"},"633":{i:0.000321498003524325,u:"../content/comp_environment/kronos_motionblur/quick_start_kronos.html",a:"Here\u0027s a quick overview of the workflow: Create a node tree with Kronos. See  Connecting Kronos . Retime your footage. See  Retiming a Sequence . If you’re not happy with the results, adjust the vector generation parameters. See  Refining the Results . If necessary, add motion blur to the retimed ...",t:"Quick Start"},"634":{i:0.000376153302244648,u:"../content/comp_environment/kronos_motionblur/connecting_kronos.html",a:"To connect Kronos: Select Time \u003e Kronos to insert a Kronos node after the sequence you want to retime. The Input Range is set automatically by the source clip when you first create the node. After that, it is only updated if you click Reset. If you intend to use  Output Speed or Frame timing, attach ...",t:"Connecting Kronos"},"635":{i:0.000482731354167608,u:"../content/comp_environment/kronos_motionblur/retiming_sequence.html",a:"Kronos allows you to retime a sequence by speed or by frame. Speed retimes describe the retime by a percentage of full speed, either against the output or input frames. For example, the default setting Output Speed = 0.5 is equal to a 50% retime on the output frames. Frame retimes  describe the ...",t:"Retiming a Sequence"},"636":{i:0.000581316713913776,u:"../content/comp_environment/kronos_motionblur/refining_results.html",a:"To refine the results: To have the motion vectors displayed in the Viewer, expand the Advanced control and enable Overlay Vectors. Forward motion vectors are drawn in red, and backward motion vectors in blue. Motion vectors displayed in the Viewer are added to your output if you don’t turn off the ...",t:"Refining the Results"},"637":{i:0.0012649494005946,u:"../content/comp_environment/kronos_motionblur/adding_motion_blur.html",a:"To add motion blur: In the Shutter controls, select a suitable Shutter Time, depending on the amount of blur you wish to add. This sets the equivalent shutter time of the retimed sequence. For example, a shutter time of 0.5 is equivalent to a 180 degree mechanical shutter, so at 24 frames per second ...",t:"Adding Motion Blur"},"638":{i:0.000635027210304963,u:"../content/comp_environment/kronos_motionblur/motionblur.html",a:"MotionBlur adds realistic motion blur to a sequence. It uses the same techniques and technology as the motion blur found in Kronos, but presents the controls in a less complex, more user friendly way. However, if you need precise control over the motion vectors used for adding blur, or a large ...",t:"MotionBlur"},"639":{i:0.000321498003524325,u:"../content/comp_environment/kronos_motionblur/quick_start_motionblur.html",a:"Here\u0027s a quick overview of the workflow: Create a node tree with MotionBlur. See  Connecting MotionBlur . Adjust the amount and quality of the motion blur produced. See  Adjusting MotionBlur Controls . You can check Use GPU if available to have the node run on the graphics processing unit (GPU) ...",t:"Quick Start"},"640":{i:0.000412590168058198,u:"../content/comp_environment/kronos_motionblur/connecting_motionblur.html",a:"To connect MotionBlur: Select Filter \u003e MotionBlur to insert a MotionBlur node after the clip you want to add motion blur to. If your sequence is composed of a foreground object moving over a background, the motion estimation is likely to get confused at the edge between the two. To fix this, add a ...",t:"Connecting MotionBlur"},"641":{i:0.000587943133331722,u:"../content/comp_environment/kronos_motionblur/adjusting_motionblur_controls.html",a:"To adjust MotionBlur controls: Select a suitable Shutter Time, depending on the amount of blur you wish to add. This sets the equivalent shutter time of the retimed sequence. For example, a shutter time of 0.5 is equivalent to a 180 degree mechanical shutter, so at 24 frames per second the exposure ...",t:"Adjusting MotionBlur Controls"},"642":{i:0.00160524582171556,u:"../content/comp_environment/lens_distortion/adding_removing_lens_distortion.html",a:"Nuke\u0027s  LensDistortion node allows you to distort or undistort an image according to a radial distortion model. Quick Start Here\u0027s a quick overview of the workflow: Read in an input sequence, connect it to a Lens Distortion node (Transform \u003e LensDistortion), and connect the output to a Viewer. To ...",t:"Working with Lens Distortion"},"643":{i:0.000516425087881334,u:"../content/comp_environment/lens_distortion/analyzing_distortion_image.html",a:"Image analysis estimates the lens distortion in a sequence (and sequence only, you can’t perform this analysis on a still image) automatically. It tracks features through the sequence and ﬁnds the distortion model that best describes the way the same 3D structure is projected onto different parts of ...",t:"Calculating Lens Distortion Automatically"},"644":{i:0.000516425087881334,u:"../content/comp_environment/lens_distortion/analyzing_distortion_grid.html",a:"Grid analysis estimates the distortion from a checkerboard or thin line grid, for greater accuracy. As a general rule, if you have a grid you can use to calculate your lens distortion, you should use grid analysis to do this. To analyze a grid, do the following: To estimate the distortion from a ...",t:"Analyzing Distortion Using a Grid"},"645":{i:0.000516425087881334,u:"../content/comp_environment/lens_distortion/analyzing_distortion_lines.html",a:"Line analysis estimates the distortion from lines drawn manually along features in the input that are known to be straight. This can be useful if you have a single image to undistort and no grid available, and can’t therefore use grid analysis or image analysis. Another case for using line analysis ...",t:"Analyzing Distortion Using Lines"},"646":{i:0.000516425087881334,u:"../content/comp_environment/lens_distortion/adjusting_lensdistortion.html",a:"After you’ve estimated your lens distortion, you can view the values on the LensDistortion tab. You can also change these to apply distortion to the input directly.  Output Type - Select your output type depending on whether you want to distort the input image directly or just preserve the ...",t:"Adjusting LensDistortion Parameters"},"647":{i:0.000662748098218213,u:"../content/comp_environment/lens_distortion/applying_distortion_another_image.html",a:"You can use the LensDistortion node to analyze the distortion on one image or grid, and then apply that distortion to another image. Do the following: Use the LensDistortion node to analyze an image or grid to get the distortion parameters. Make sure Output Type is set to Image on the LensDistortion ...",t:"Calculating the Distortion on One Image and Applying it to Another"},"648":{i:0.000662748098218213,u:"../content/comp_environment/lens_distortion/applying_lens_distortion_card.html",a:"You can use the calculated lens distortion values to distort an image projected onto a card in 3D. Do the following: Open the Card Parameters folder on the LensDistortion tab. Hold down Ctrl/Cmd and drag the x, y and z values from the scale parameter’s values on to the corresponding fields on the ...",t:"Applying Lens Distortion to a Card Node"},"649":{i:0.000604752306207229,u:"../content/comp_environment/planartracker/tracking_planar_surfaces.html",a:"PlanarTracker is a powerful tool for tracking surfaces that lie on a plane in your source footage.  About Planar Tracking Planar tracking is often better than tracking individual points (with the Tracker node for instance) as it takes a great deal more information into account and gives you a more ...",t:"Tracking with PlanarTracker"},"650":{i:0.00150967144775735,u:"../content/comp_environment/planartracker/tracking_plane.html",a:"Before you can track a plane, you need to draw one using the Roto node. Drawing a Plane to Track  You can use the PlanarTracker to track rigid objects and objects that deform slightly throughout the track. As the PlanarTracker tries to fit a plane to the object to be tracked, rigid objects obtain ...",t:"Tracking a Plane"},"651":{i:0.000321498003524325,u:"../content/comp_environment/planartracker/reusing_track_result.html",a:"You can reuse an entire tracked plane or a single track. Reusing a Tracked Plane You can use a plane you’ve already tracked to analyze a larger plane situated on the same plane.  Make sure you’re in the same frame as you used to draw the previous shape. Draw a shape on the same plane as your ...",t:"Reusing a Track Result"},"652":{i:0.000321498003524325,u:"../content/comp_environment/planartracker/placing_image_planar_surface.html",a:"When you’ve tracked a planar surface on your footage, you might want to place an image on it. To place an image on the tracked planar surface, do the following:  Ensure you’re on the reference frame you’ve drawn the roto shape on, and select the PlanarTrackLayer you want to use in the Create New ...",t:"Placing an Image on the Planar Surface"},"653":{i:0.00118566687351382,u:"../content/comp_environment/cameratracker/camera_tracking.html",a:"Nuke’s CameraTracker node is designed to provide an integrated camera tracking or match-moving tool, which allows you to create a virtual camera whose movement matches that of your original camera. Tracking camera movement in a 2D footage enables you to add virtual 3D objects to your 2D footage. ...",t:"Camera Tracking"},"654":{i:0.000512081910293562,u:"../content/comp_environment/cameratracker/connecting_ct.html",a:"To connect the CameraTracker node: Read in and select the clip you want to track. Click 3D \u003e CameraTracker. If you want to omit a part of the scene from being tracked, connect a matte to the Mask input. Note that, unlike the Source input, this input is hidden and appears as a small triangle on the ...",t:"Connecting the CameraTracker Node"},"655":{i:0.00212093380644177,u:"../content/comp_environment/cameratracker/masking.html",a:"Tracking works best on fixed, rigid parts of the scene so that each track can create a single, fixed 3D point. The solver uses these 3D points to work out the camera path. Moving elements and burn-ins do not have a fixed 3D point in the world and should be masked out before tracking. To mask regions ...",t:"Masking Out Regions of the Image"},"656":{i:0.000399023685562183,u:"../content/comp_environment/cameratracker/multiview_scripts.html",a:"CameraTracker can track and solve stereoscopic or multi-view projects in much the same way  as single view projects.  Connect the CameraTracker node as described in  Connecting the CameraTracker Node . Use the CameraTracker or Settings tab Principal View dropdown to select the view used to create ...",t:"Working with Multi-View Scripts"},"657":{i:0.000399023685562183,u:"../content/comp_environment/cameratracker/camera_settings.html",a:"Camera settings relate to the physical aspects of the camera used on set. Accurate physical camera data produces a better camera track and solution. Select the motion type of the on set camera from the CameraTracker tab Camera Motion dropdown menu. This is linked to a control of the same name on the ...",t:"Setting Camera Parameters"},"658":{i:0.00256013687004992,u:"../content/comp_environment/cameratracker/tracking_sequences.html",a:"In Sequence mode, CameraTracker tracks the footage attached to the Source input and defines a set of 2D feature tracks that correspond to fixed points in the scene.  If you intend to remove lens distortion manually using a separate LensDistortion node, you should do that before you track the ...",t:"Tracking in Sequence Mode"},"659":{i:0.000321498003524325,u:"../content/comp_environment/cameratracker/viewing_sequence_tracks.html",a:"Once tracking is complete, scrub through the timeline to examine the tracked features. The points represent the features and the vectors the track length calculated for the associated feature. Hover over a point to display its length, in frames. Consider masking out areas where tracks are ...",t:"Viewing Track Data"},"660":{i:0.00127158765400509,u:"../content/comp_environment/cameratracker/troubleshooting_sequences.html",a:"Some sequences are inevitably going to cause problems. There are a number of pre-tracking checks and post-tracking refinement controls to assist CameraTracker. Pre-Tracking Checks Play through the sequence before tracking and mask out any problem areas in the scene. Large moving objects can confuse ...",t:"Troubleshooting Sequence Tracks"},"661":{i:0.000783465375056019,u:"../content/comp_environment/cameratracker/extending_tracks.html",a:"CameraTracker allows you to extend an existing set of tracking data by adding new frames, such as when more frames become available from a shoot.  You can update tracking data as often as you like before solving, but once you\u0027ve solved the camera position, updating tracking data should only be used ...",t:"Extending Existing Camera Tracks"},"662":{i:0.000813701745989164,u:"../content/comp_environment/cameratracker/retracking_sequences.html",a:"After refining your feature points, you may not need to retrack the entire sequence. You can use Update Track to analyze a specific frame range. Refine your features using the controls described previously. Click Update Track. A dialog displays allowing you to set the frame range to update. Set the ...",t:"Retracking Partial Frame Ranges"},"663":{i:0.000487085305975293,u:"../content/comp_environment/cameratracker/tracking_stills.html",a:"In Stills mode, CameraTracker tracks the reference frames in the Source input and analyzes the input in two stages. Tracking defines the set of 2D feature tracks that correspond to fixed rigid points in the scene, then the solver calculates the camera path and projection that creates a 3D point for ...",t:"Tracking in Stills Mode"},"664":{i:0.000390502775626093,u:"../content/comp_environment/cameratracker/stills_guidelines.html",a:"Still tracking relies on good input to produce good tracking output, so it\u0027s vital that you capture good still photographs that CameraTracker can interpret correctly. CameraTracker has different requirements depending on the subject of the stills. For example, stills for a near-flat scenes are ...",t:"Still Photography Guidelines"},"665":{i:0.000544890601759412,u:"../content/comp_environment/cameratracker/tracking_properties_stills.html",a:"Before you do anything else, you need to tell CameraTracker which still frames you want it to track and how it should distribute the tracking features on each frame. Then, you can track your still frames. Selecting the Frames to Track On the CameraTracker tab of the CameraTracker properties, ensure ...",t:"Tracking Still Frames"},"666":{i:0.000544890601759412,u:"../content/comp_environment/cameratracker/viewing_still_tracks.html",a:"Once tracking is complete, you can review how CameraTracker connected the analyzed frames: Do one of the following: Switch the Thumbnails control above the Viewer to Tracked. CameraTracker displays the frames that are connected to the current frame in the thumbnail gallery at the bottom of the ...",t:"Viewing Reference Frames and Track Data"},"667":{i:0.000622084514826072,u:"../content/comp_environment/cameratracker/disconnected_frames.html",a:"Auto-tracking stills is not perfect and may throw out some disconnected frames, most likely due to a large change in viewpoint. After tracking, set the Thumbnails control above the Viewer to All and hover over images in the thumbnail strip. Thumbnails highlighted in red were not matched with the ...",t:"Disconnected Frame Sets"},"668":{i:0.000710146135239182,u:"../content/comp_environment/cameratracker/troubleshooting_stills.html",a:"Some stills sequences are inevitably going to cause problems. There are a number of pre-tracking checks and post-tracking refinement controls to assist CameraTracker. You can improve tracking data by adding User Tracks. See  Working with User Tracks  for more information. Pre-tracking Checks For ...",t:"Troubleshooting Still Tracks"},"669":{i:0.00211833031254686,u:"../content/comp_environment/cameratracker/tracking_usertracks.html",a:"User Tracks are placed manually, rather then being automatically seeded by CameraTracker, and can be used to improve or even replace auto tracking data. They can also be used to link unmatched reference frames together when tracking stills. You can create User Tracks before tracking and solving to ...",t:"Working with User Tracks"},"670":{i:0.000621600619368032,u:"../content/comp_environment/cameratracker/adding_usertracks.html",a:"You can add as many User Tracks as required, depending on what you intend to accomplish. For example, auto-track assist may only require one or two User Tracks, whereas manual tracking would require at least eight User Tracks. Enable the fast-add button   at the top of the Viewer and click in the ...",t:"Adding and Positioning User Tracks"},"671":{i:0.0017000010996434,u:"../content/comp_environment/cameratracker/usertrack_methods.html",a:"User Tracks can be  tracked automatically or manually, extracted from auto-tracking data, and imported from a Tracker node. Auto User Tracks The easiest way to get started with User Tracks is using the Autotrack feature, but you can create tracks totally independent of auto-tracking. After placing ...",t:"User Tracking Methods"},"672":{i:0.000621600619368032,u:"../content/comp_environment/cameratracker/tracking_assists.html",a:"Auto-tracking data can be improved by seeding User Tracks in a sequence, as CameraTracker assumes manually placed tracks are superior to auto-tracking. Re-tracking after adding User Tracks forces CameraTracker to recalculate auto-tracks using more accurate data. Track your sequence using the steps ...",t:"Tracking Assists"},"673":{i:0.000872635580499811,u:"../content/comp_environment/cameratracker/manual_tracking.html",a:"Sometimes, a scene can be difficult to track automatically. For example, you might be tracking a set of still photos of a scene with a very wide baseline between images. Alternatively, you might already have 2D track data from an earlier process that you want to get a solve from. In cases like this, ...",t:"Tracking a Scene Manually"},"674":{i:0.000885990327538656,u:"../content/comp_environment/cameratracker/linking_stills.html",a:"During stills tracking, the links between reference frames can fail. This can occur for a number of reasons, such as a lack of overlap between stills. You can help CameraTracker by adding  User Tracks on features common to the frames before auto-tracking. Use the steps described in  Working with ...",t:"Linking Still Reference Frames"},"675":{i:0.000776527214421153,u:"../content/comp_environment/cameratracker/3d_survey_points.html",a:"If you create a User Track, you can assign it as a known 3D survey point. This tells CameraTracker which points in your 2D footage go with their counterparts on your 3D model, allowing it to solve the camera to match the known 3D points and achieve the best results. 3D survey points have replaced ...",t:"Assigning 3D Survey Points"},"676":{i:0.00133098244454896,u:"../content/comp_environment/cameratracker/solving_camera_position.html",a:"When you’re happy with the features that you’ve tracked, you can solve the camera position. CameraTracker uses the tracking\ninformation to calculate the camera position and add position information to the tracked feature points in the Viewer. In the CameraTracker properties panel, click Solve. The ...",t:"Solving the Camera Position"},"677":{i:0.000321498003524325,u:"../content/comp_environment/cameratracker/viewing_solve_data.html",a:"Once the solve data is placed in the Viewer, you can zoom in to display the points more clearly. You can control what appears in the Viewer using the Display controls on the Settings tab: Show tracks - show or hide the 2D tracking information. Show projected 3D points - show or hide the 2D position ...",t:"Viewing Solve Data"},"678":{i:0.000412590168058198,u:"../content/comp_environment/cameratracker/troubleshooting_solves.html",a:"CameraTracker has several troubleshooting workflows available to improve solve accuracy, but ultimately, good solves rely on good tracking data.  Using Curve Thresholds to Delete Tracks You can use the threshold controls on the AutoTracks tab to dynamically reject tracks and remove them  to improve ...",t:"Troubleshooting Solves"},"679":{i:0.000543483208116489,u:"../content/comp_environment/cameratracker/updating_solves.html",a:"CameraTracker allows you to add more frames to an existing camera solve using updated tracking data. It is usually not possible to extend the range very far (about 10-15% of the original range), because the existing solve locks the 3D points in place, so matching new 2D tracking data to 3D points ...",t:"Updating Solves with Extended Tracking Data"},"680":{i:0.000490115850096056,u:"../content/comp_environment/cameratracker/adjusting_scene.html",a:"When the tracking and solving processes are complete, you can use the  solve data to align and scale the scene before adding cameras, point clouds, objects, and so on. You can: Set the ground plane, axes, or origin for the scene. See  Setting the Ground Plane and Axes . Manually adjust the scene ...",t:"Adjusting the Scene"},"681":{i:0.000460366040570847,u:"../content/comp_environment/cameratracker/setting_groundplane.html",a:"A solved camera has no notion of where the ground plane is in the scene, which can produce an unexpected offset and angle relative to where you\u0027d expect the ground to be in 3D space.  Setting the ground plane or set of axes is designed to provide CameraTracker with a sensible frame of reference. ...",t:"Setting the Ground Plane and Axes"},});